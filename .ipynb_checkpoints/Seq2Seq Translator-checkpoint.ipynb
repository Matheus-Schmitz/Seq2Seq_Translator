{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZKkobWqO-mp"
   },
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23104,
     "status": "ok",
     "timestamp": 1590355191863,
     "user": {
      "displayName": "Matheus Schmitz",
      "photoUrl": "",
      "userId": "05041072222578354690"
     },
     "user_tz": 180
    },
    "id": "kz8JKcJWjSWp",
    "outputId": "b2003527-eddf-4a96-9cbb-6a8938b9c389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# File manipulation imports for Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir(\"/content/drive/My Drive/Colab Notebooks/Seq2Seq_Translator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GhzIA2HQO0wd"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math\n",
    "import time\n",
    "import spacy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YUCwvwDKPtrD"
   },
   "outputs": [],
   "source": [
    "# Setting the device to cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4020,
     "status": "ok",
     "timestamp": 1590355205517,
     "user": {
      "displayName": "Matheus Schmitz",
      "photoUrl": "",
      "userId": "05041072222578354690"
     },
     "user_tz": 180
    },
    "id": "JLOt-57TP1MC",
    "outputId": "7d5b7159-8b9c-44b2-cd87-00d11778246c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 24 21:20:08 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P0    31W / 250W |   2157MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BzRIiGQ9QHRw"
   },
   "source": [
    "# Loading Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8647,
     "status": "ok",
     "timestamp": 1590355210178,
     "user": {
      "displayName": "Matheus Schmitz",
      "photoUrl": "",
      "userId": "05041072222578354690"
     },
     "user_tz": 180
    },
    "id": "aHCkX_UGP9UT",
    "outputId": "f667bea7-ed27-4afd-cc27-677f38a78965"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
      "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "# Download english dictionary\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13242,
     "status": "ok",
     "timestamp": 1590355214802,
     "user": {
      "displayName": "Matheus Schmitz",
      "photoUrl": "",
      "userId": "05041072222578354690"
     },
     "user_tz": 180
    },
    "id": "HRGfgnCNQRXA",
    "outputId": "c44b362f-c74a-4a98-b84e-ae0eda8b42c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (46.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.4.5.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('de_core_news_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
      "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
      "You can now load the model via spacy.load('de')\n"
     ]
    }
   ],
   "source": [
    "# Download german dictionary\n",
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YcGdOd_CQWjW"
   },
   "outputs": [],
   "source": [
    "# Loading dictionaries\n",
    "spacy_english = spacy.load('en')\n",
    "spacy_german = spacy.load('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D4NCF57BQhlA"
   },
   "outputs": [],
   "source": [
    "# Tokenization function: english\n",
    "# The '[::-1]' is needed because the text order is flipped\n",
    "def tokenize_english(text):\n",
    "    return [token.text for token in spacy_english.tokenizer(text)][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4kttdoBESSPC"
   },
   "outputs": [],
   "source": [
    "# Tokenization function: german\n",
    "def tokenize_german(text):\n",
    "    return [token.text for token in spacy_german.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKK74yRlSVrm"
   },
   "outputs": [],
   "source": [
    "# Source language\n",
    "SOURCE = Field(tokenize = tokenize_english, init_token = '<sos>', eos_token = '<eos>', lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aaI2gTPIS3sT"
   },
   "outputs": [],
   "source": [
    "# Target language\n",
    "TARGET = Field(tokenize = tokenize_german, init_token = '<sos>', eos_token = '<eos>', lower = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5g_USJXdS9TU"
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.en', '.de'), fields = (SOURCE, TARGET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3709,
     "status": "ok",
     "timestamp": 1590356392533,
     "user": {
      "displayName": "Matheus Schmitz",
      "photoUrl": "",
      "userId": "05041072222578354690"
     },
     "user_tz": 180
    },
    "id": "ozKfEdguU5MY",
    "outputId": "9f8ac66c-bbfe-4635-da16-a824e3a16de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'bushes', 'many', 'near', 'outside', 'are', 'males', 'white', ',', 'young', 'two']\n",
      "['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.']\n"
     ]
    }
   ],
   "source": [
    "# Vizualising the train data\n",
    "print(train_data.examples[0].src)\n",
    "print(train_data.examples[0].trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3555,
     "status": "ok",
     "timestamp": 1590356392534,
     "user": {
      "displayName": "Matheus Schmitz",
      "photoUrl": "",
      "userId": "05041072222578354690"
     },
     "user_tz": 180
    },
    "id": "Vi7NrMOzVS4P",
    "outputId": "7c77446a-150c-4668-b774-c8b3b48f59ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 29000\n",
      "Validation dataset length: 1014\n",
      "Test dataset length: 1000\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset length: ' + str(len(train_data.examples)))\n",
    "print('Validation dataset length: ' + str(len(valid_data.examples)))\n",
    "print('Test dataset length: ' + str(len(test_data.examples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KrvmzWkAVxGQ"
   },
   "outputs": [],
   "source": [
    "# Creating the SOURCE and TARGET vocabularies\n",
    "SOURCE.build_vocab(train_data, min_freq = 2)\n",
    "TARGET.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cwaNd3NHWD0I"
   },
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tuwMNldXWByI"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    # Constructor method\n",
    "    def __init__(self, input_dims, emb_dims, hid_dims, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Model layers\n",
    "        self.hid_dims = hid_dims\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dims, emb_dims)\n",
    "        self.rnn = nn.LSTM(emb_dims, hid_dims, n_layers, dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # Forward method for training\n",
    "    def forward(self, src):\n",
    "        \n",
    "        # Model execution\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (h, cell) = self.rnn(embedded)\n",
    "\n",
    "        return h, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EyMlI2RlXWs-"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    # Constructor method\n",
    "    def __init__(self, output_dims, emb_dims, hid_dims, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Model layers\n",
    "        self.output_dims = output_dims\n",
    "        self.hid_dims = hid_dims\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dims, emb_dims)\n",
    "        self.rnn = nn.LSTM(emb_dims, hid_dims, n_layers, dropout = dropout)\n",
    "        self.fc_out = nn.Linear(hid_dims, output_dims)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    # Forward method for training\n",
    "    def forward(self, input, h, cell):\n",
    "              \n",
    "        # Model execution\n",
    "        input = input.unsqueeze(0)   \n",
    "        embedded = self.dropout(self.embedding(input))     \n",
    "        output, (h, cell) = self.rnn(embedded, (h, cell))\n",
    "        pred = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        return pred, h, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJ77yQPaX5aD"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    # Constructor method\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Model components\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    # Forward method for training\n",
    "    def forward(self, src, trg, teacher_forcing_rate = 0.5):\n",
    "        \n",
    "        # Model execution\n",
    "        batch_size = trg.shape[1]\n",
    "        target_length = trg.shape[0]\n",
    "        target_vocab_size = self.decoder.output_dims\n",
    "        outputs = torch.zeros(target_length, batch_size, target_vocab_size).to(self.device)\n",
    "        h, cell = self.encoder(src)\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, target_length):\n",
    "\n",
    "            output, h, cell = self.decoder(input, h, cell)\n",
    "            outputs[t] = output\n",
    "            top = output.argmax(1) \n",
    "            input = trg[t] if (random.random() < teacher_forcing_rate) else top\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wtIpLsEXavxJ"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "input_dimensions = len(SOURCE.vocab)\n",
    "output_dimensions = len(TARGET.vocab)\n",
    "encoder_embedding_dimensions = 256\n",
    "decoder_embedding_dimensions = 256\n",
    "hidden_layer_dimensions = 512\n",
    "num_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "epochs = 30\n",
    "grad_clip = 1\n",
    "lowest_validation_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VjbQcEyLazAU"
   },
   "outputs": [],
   "source": [
    "# Data generators\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), \n",
    "                                                                        batch_size = batch_size, \n",
    "                                                                        device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GJcaetja-1F"
   },
   "outputs": [],
   "source": [
    "# Enconder instance\n",
    "encod = Encoder(input_dimensions, \n",
    "                encoder_embedding_dimensions,\n",
    "                hidden_layer_dimensions, \n",
    "                num_layers, \n",
    "                encoder_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDq9jVO2bTfD"
   },
   "outputs": [],
   "source": [
    "# Decor instance\n",
    "decod = Decoder(output_dimensions, \n",
    "                decoder_embedding_dimensions,\n",
    "                hidden_layer_dimensions, \n",
    "                num_layers, \n",
    "                decoder_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1pv6UscDbVlj"
   },
   "outputs": [],
   "source": [
    "# Model instance\n",
    "model = Seq2Seq(encod, decod, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11170,
     "status": "ok",
     "timestamp": 1590356403465,
     "user": {
      "displayName": "Matheus Schmitz",
      "photoUrl": "",
      "userId": "05041072222578354690"
     },
     "user_tz": 180
    },
    "id": "YDpfKx5bbY51",
    "outputId": "0bb52741-48d0-44df-db65-3cdaab936e3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(7855, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=7855, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 168,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hv_X9VdfbcxY"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10938,
     "status": "ok",
     "timestamp": 1590356404990,
     "user": {
      "displayName": "Matheus Schmitz",
      "photoUrl": "",
      "userId": "05041072222578354690"
     },
     "user_tz": 180
    },
    "id": "4qx3fdaibm7z",
    "outputId": "9243e6f3-802c-4d44-ccea-2f6a9e548554"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(7855, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=7855, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 170,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Including the weight initialization function on the model\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2F5JPjqMdyzv"
   },
   "outputs": [],
   "source": [
    "# Defining the loss function to calculate model error\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TARGET.vocab.stoi[TARGET.pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8zmJQsLdy2L"
   },
   "outputs": [],
   "source": [
    "# Creating an optimizer to update the model weights after each epoch\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fsniFs59bt69"
   },
   "outputs": [],
   "source": [
    "def train_model(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    # Initialize the training method\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize epoch error\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # Loop through iterator (data generator)\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        # Collect source and target data\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Predict\n",
    "        output = model(src, trg)\n",
    "        \n",
    "        # Adjust prediction shape\n",
    "        output_dims = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dims)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        # Initialize backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Calculate the derivative gradients to update weights\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        # Apply weight optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Store epoch error\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CksvU0HAb3Js"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, iterator, criterion):\n",
    "    \n",
    "    # Initialize evaluation method\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize epoch error\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # Predicting\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        # Loop through iterator (data generator)\n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            # Extract source and target data\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            # Predict\n",
    "            output = model(src, trg, 0)\n",
    "\n",
    "            # Adjust prediction shape\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            # Model loss\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            # Store epoch error\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vbHNE_zfczaK"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1070040,
     "status": "ok",
     "timestamp": 1590357495386,
     "user": {
      "displayName": "Matheus Schmitz",
      "photoUrl": "",
      "userId": "05041072222578354690"
     },
     "user_tz": 180
    },
    "id": "jNi9-86xcuyN",
    "outputId": "5b003904-616b-4994-827f-4d1203a8e0bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 53.0s\n",
      "\t Training error: 3.0340\n",
      "\t Validation Error: 3.6917\n",
      "Epoch: 02 | Time: 53.0s\n",
      "\t Training error: 2.7115\n",
      "\t Validation Error: 3.6485\n",
      "Epoch: 03 | Time: 53.0s\n",
      "\t Training error: 2.5477\n",
      "\t Validation Error: 3.5898\n",
      "Epoch: 04 | Time: 53.0s\n",
      "\t Training error: 2.4221\n",
      "\t Validation Error: 3.5336\n",
      "Epoch: 05 | Time: 53.0s\n",
      "\t Training error: 2.2868\n",
      "\t Validation Error: 3.5662\n",
      "Epoch: 06 | Time: 53.0s\n",
      "\t Training error: 2.1759\n",
      "\t Validation Error: 3.6335\n",
      "Epoch: 07 | Time: 53.0s\n",
      "\t Training error: 2.0799\n",
      "\t Validation Error: 3.5997\n",
      "Epoch: 08 | Time: 53.0s\n",
      "\t Training error: 1.9717\n",
      "\t Validation Error: 3.6085\n",
      "Epoch: 09 | Time: 54.0s\n",
      "\t Training error: 1.9058\n",
      "\t Validation Error: 3.6265\n",
      "Epoch: 10 | Time: 54.0s\n",
      "\t Training error: 1.8162\n",
      "\t Validation Error: 3.6797\n",
      "Epoch: 11 | Time: 54.0s\n",
      "\t Training error: 1.7466\n",
      "\t Validation Error: 3.6288\n",
      "Epoch: 12 | Time: 54.0s\n",
      "\t Training error: 1.6704\n",
      "\t Validation Error: 3.6528\n",
      "Epoch: 13 | Time: 54.0s\n",
      "\t Training error: 1.6080\n",
      "\t Validation Error: 3.7270\n",
      "Epoch: 14 | Time: 54.0s\n",
      "\t Training error: 1.5554\n",
      "\t Validation Error: 3.7336\n",
      "Epoch: 15 | Time: 54.0s\n",
      "\t Training error: 1.4994\n",
      "\t Validation Error: 3.7599\n",
      "Epoch: 16 | Time: 53.0s\n",
      "\t Training error: 1.4450\n",
      "\t Validation Error: 3.7641\n",
      "Epoch: 17 | Time: 54.0s\n",
      "\t Training error: 1.3961\n",
      "\t Validation Error: 3.7791\n",
      "Epoch: 18 | Time: 54.0s\n",
      "\t Training error: 1.3473\n",
      "\t Validation Error: 3.8986\n",
      "Epoch: 19 | Time: 54.0s\n",
      "\t Training error: 1.3109\n",
      "\t Validation Error: 3.9076\n",
      "Epoch: 20 | Time: 54.0s\n",
      "\t Training error: 1.2673\n",
      "\t Validation Error: 3.9060\n"
     ]
    }
   ],
   "source": [
    "# Loop through epochs to train odel\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Store start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training\n",
    "    train_loss = train_model(model, train_iterator, optimizer, criterion, grad_clip)\n",
    "    \n",
    "    # Validation\n",
    "    valid_loss = evaluate_model(model, valid_iterator, criterion)\n",
    "    \n",
    "    # Store end time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Check lowest error and save the model by doing a checkpoint of the best performing model\n",
    "    if valid_loss < lowest_validation_loss:\n",
    "        lowest_validation_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'models/seq2seq.pt')\n",
    "    \n",
    "    # Print\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {np.round(end_time-start_time,0)}s')\n",
    "    print(f'\\t Training error: {train_loss:.4f}')\n",
    "    print(f'\\t Validation Error: {valid_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tv_hNzGueMnY"
   },
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1067936,
     "status": "ok",
     "timestamp": 1590357495390,
     "user": {
      "displayName": "Matheus Schmitz",
      "photoUrl": "",
      "userId": "05041072222578354690"
     },
     "user_tz": 180
    },
    "id": "2Zm_CblteOU_",
    "outputId": "958066e1-5fe7-4b93-f70c-7bdfc6e878ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 182,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading trained model\n",
    "model.load_state_dict(torch.load('models/seq2seq.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GMvUsK7lj5yD"
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "test_loss = evaluate_model(model, test_iterator, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1068126,
     "status": "ok",
     "timestamp": 1590357495879,
     "user": {
      "displayName": "Matheus Schmitz",
      "photoUrl": "",
      "userId": "05041072222578354690"
     },
     "user_tz": 180
    },
    "id": "TEtkBwOEkBIv",
    "outputId": "00a7c702-056d-45c6-c313-24aa7efc56c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: 3.5281\n"
     ]
    }
   ],
   "source": [
    "# Test error\n",
    "print(f'Test Error: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qVzq8rnAkH9J"
   },
   "source": [
    "# Translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OPa6bDNvkJMt"
   },
   "outputs": [],
   "source": [
    "def translate_language(model, iterator, num_translations = 5):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        # Loop through iterador\n",
    "        for i, batch in enumerate(iterator):\n",
    "            \n",
    "            # While inside the num_translations, translate\n",
    "            if i < num_translations :\n",
    "                \n",
    "                # Extract SOURCE and TARGET\n",
    "                # Doing so to compare the predicted translation with the true translation\n",
    "                src = batch.src\n",
    "                trg = batch.trg\n",
    "\n",
    "                # Model prediction\n",
    "                output = model(src, trg, 0)\n",
    "                \n",
    "                # All predictions\n",
    "                preds = torch.tensor([[torch.argmax(x).item()] for x in output])\n",
    "                \n",
    "                # Prints\n",
    "                print('Original English Text: ' + str([SOURCE.vocab.itos[x] for x in src][1:-1][::-1]))\n",
    "                print('Translated German Text (Expected Output): ' + str([TARGET.vocab.itos[x] for x in trg][1:-1]))\n",
    "                print('Translated German Text (Model Prediction): ' + str([TARGET.vocab.itos[x] for x in preds][1:-1]))\n",
    "                print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TXyW-atZk5sa"
   },
   "outputs": [],
   "source": [
    "# Generating random text to be translated\n",
    "_, _, iterator_translate = BucketIterator.splits((train_data, valid_data, test_data), \n",
    "                                                 batch_size = 1, \n",
    "                                                 device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1067477,
     "status": "ok",
     "timestamp": 1590357495882,
     "user": {
      "displayName": "Matheus Schmitz",
      "photoUrl": "",
      "userId": "05041072222578354690"
     },
     "user_tz": 180
    },
    "id": "kARtfOGnlGTl",
    "outputId": "fbbaa08c-1d59-4081-c3e2-72ccce878a8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original English Text: ['two', 'men', 'wearing', 'hats', '.']\n",
      "Translated German Text (Expected Output): ['zwei', 'männer', 'mit', 'mützen', '.']\n",
      "Translated German Text (Model Prediction): ['zwei', 'männer', 'mit', 'sonnenbrillen', '.']\n",
      "\n",
      "\n",
      "Original English Text: ['young', 'woman', 'climbing', 'rock', 'face']\n",
      "Translated German Text (Expected Output): ['junge', 'frau', 'klettert', 'auf', 'felswand']\n",
      "Translated German Text (Model Prediction): ['eine', 'junge', 'frau', ',', 'die']\n",
      "\n",
      "\n",
      "Original English Text: ['a', 'woman', 'is', 'playing', 'volleyball', '.']\n",
      "Translated German Text (Expected Output): ['eine', 'frau', 'spielt', 'volleyball', '.']\n",
      "Translated German Text (Model Prediction): ['eine', 'frau', 'spielt', 'volleyball', '.']\n",
      "\n",
      "\n",
      "Original English Text: ['three', 'men', 'are', 'walking', 'up', 'hill', '.']\n",
      "Translated German Text (Expected Output): ['drei', 'männer', 'gehen', 'bergauf', '.']\n",
      "Translated German Text (Model Prediction): ['drei', 'männer', 'gehen', 'durch', 'den']\n",
      "\n",
      "\n",
      "Original English Text: ['an', 'army', 'officer', 'is', 'inspecting', 'something', '.']\n",
      "Translated German Text (Expected Output): ['ein', '<unk>', 'inspiziert', 'etwas', '.']\n",
      "Translated German Text (Model Prediction): ['ein', '<unk>', 'wird', '<unk>', '.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Translation\n",
    "translation = translate_language(model, iterator_translate)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOtuXbN3s7QOOkDoRnD95ZZ",
   "collapsed_sections": [
    "cwaNd3NHWD0I",
    "vbHNE_zfczaK",
    "Tv_hNzGueMnY",
    "qVzq8rnAkH9J"
   ],
   "name": "Seq2Seq Translator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
