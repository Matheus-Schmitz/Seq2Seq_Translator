{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2Seq Translator.ipynb","provenance":[],"collapsed_sections":["cwaNd3NHWD0I","vbHNE_zfczaK","Tv_hNzGueMnY","qVzq8rnAkH9J"],"authorship_tag":"ABX9TyOtuXbN3s7QOOkDoRnD95ZZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"TZKkobWqO-mp","colab_type":"text"},"source":["# Load Packages"]},{"cell_type":"code","metadata":{"id":"kz8JKcJWjSWp","colab_type":"code","outputId":"b2003527-eddf-4a96-9cbb-6a8938b9c389","executionInfo":{"status":"ok","timestamp":1590355191863,"user_tz":180,"elapsed":23104,"user":{"displayName":"Matheus Schmitz","photoUrl":"","userId":"05041072222578354690"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# File manipulation imports for Google Colab\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/My Drive/Colab Notebooks/Seq2Seq_Translator\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GhzIA2HQO0wd","colab_type":"code","colab":{}},"source":["# Imports\n","import math\n","import time\n","import spacy\n","import torch\n","import random\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchtext\n","from torchtext.datasets import Multi30k\n","from torchtext.data import Field, BucketIterator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YUCwvwDKPtrD","colab_type":"code","colab":{}},"source":["# Setting the device to cuda\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JLOt-57TP1MC","colab_type":"code","outputId":"7d5b7159-8b9c-44b2-cd87-00d11778246c","executionInfo":{"status":"ok","timestamp":1590355205517,"user_tz":180,"elapsed":4020,"user":{"displayName":"Matheus Schmitz","photoUrl":"","userId":"05041072222578354690"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["# Check GPU\n","!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sun May 24 21:20:08 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    31W / 250W |   2157MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BzRIiGQ9QHRw","colab_type":"text"},"source":["# Loading Dictionaries"]},{"cell_type":"code","metadata":{"id":"aHCkX_UGP9UT","colab_type":"code","outputId":"f667bea7-ed27-4afd-cc27-677f38a78965","executionInfo":{"status":"ok","timestamp":1590355210178,"user_tz":180,"elapsed":8647,"user":{"displayName":"Matheus Schmitz","photoUrl":"","userId":"05041072222578354690"}},"colab":{"base_uri":"https://localhost:8080/","height":496}},"source":["# Download english dictionary\n","!python -m spacy download en"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.4)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.3.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HRGfgnCNQRXA","colab_type":"code","outputId":"c44b362f-c74a-4a98-b84e-ae0eda8b42c4","executionInfo":{"status":"ok","timestamp":1590355214802,"user_tz":180,"elapsed":13242,"user":{"displayName":"Matheus Schmitz","photoUrl":"","userId":"05041072222578354690"}},"colab":{"base_uri":"https://localhost:8080/","height":496}},"source":["# Download german dictionary\n","!python -m spacy download de"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.6.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.4)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (46.3.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.4.5.1)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('de_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/de\n","You can now load the model via spacy.load('de')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YcGdOd_CQWjW","colab_type":"code","colab":{}},"source":["# Loading dictionaries\n","spacy_english = spacy.load('en')\n","spacy_german = spacy.load('de')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D4NCF57BQhlA","colab_type":"code","colab":{}},"source":["# Tokenization function: english\n","# The '[::-1]' is needed because the text order is flipped\n","def tokenize_english(text):\n","    return [token.text for token in spacy_english.tokenizer(text)][::-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4kttdoBESSPC","colab_type":"code","colab":{}},"source":["# Tokenization function: german\n","def tokenize_german(text):\n","    return [token.text for token in spacy_german.tokenizer(text)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eKK74yRlSVrm","colab_type":"code","colab":{}},"source":["# Source language\n","SOURCE = Field(tokenize = tokenize_english, init_token = '<sos>', eos_token = '<eos>', lower = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aaI2gTPIS3sT","colab_type":"code","colab":{}},"source":["# Target language\n","TARGET = Field(tokenize = tokenize_german, init_token = '<sos>', eos_token = '<eos>', lower = True) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5g_USJXdS9TU","colab_type":"code","colab":{}},"source":["# Train-test split\n","train_data, valid_data, test_data = Multi30k.splits(exts = ('.en', '.de'), fields = (SOURCE, TARGET))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ozKfEdguU5MY","colab_type":"code","outputId":"9f8ac66c-bbfe-4635-da16-a824e3a16de3","executionInfo":{"status":"ok","timestamp":1590356392533,"user_tz":180,"elapsed":3709,"user":{"displayName":"Matheus Schmitz","photoUrl":"","userId":"05041072222578354690"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Vizualising the train data\n","print(train_data.examples[0].src)\n","print(train_data.examples[0].trg)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['.', 'bushes', 'many', 'near', 'outside', 'are', 'males', 'white', ',', 'young', 'two']\n","['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vi7NrMOzVS4P","colab_type":"code","outputId":"7c77446a-150c-4668-b774-c8b3b48f59ff","executionInfo":{"status":"ok","timestamp":1590356392534,"user_tz":180,"elapsed":3555,"user":{"displayName":"Matheus Schmitz","photoUrl":"","userId":"05041072222578354690"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print('Train dataset length: ' + str(len(train_data.examples)))\n","print('Validation dataset length: ' + str(len(valid_data.examples)))\n","print('Test dataset length: ' + str(len(test_data.examples)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train dataset length: 29000\n","Validation dataset length: 1014\n","Test dataset length: 1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KrvmzWkAVxGQ","colab_type":"code","colab":{}},"source":["# Creating the SOURCE and TARGET vocabularies\n","SOURCE.build_vocab(train_data, min_freq = 2)\n","TARGET.build_vocab(train_data, min_freq = 2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cwaNd3NHWD0I","colab_type":"text"},"source":["# Building the Model"]},{"cell_type":"code","metadata":{"id":"tuwMNldXWByI","colab_type":"code","colab":{}},"source":["class Encoder(nn.Module):\n","    \n","    # Constructor method\n","    def __init__(self, input_dims, emb_dims, hid_dims, n_layers, dropout):\n","        super().__init__()\n","\n","        # Model layers\n","        self.hid_dims = hid_dims\n","        self.n_layers = n_layers\n","        self.embedding = nn.Embedding(input_dims, emb_dims)\n","        self.rnn = nn.LSTM(emb_dims, hid_dims, n_layers, dropout = dropout)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    # Forward method for training\n","    def forward(self, src):\n","        \n","        # Model execution\n","        embedded = self.dropout(self.embedding(src))\n","        outputs, (h, cell) = self.rnn(embedded)\n","\n","        return h, cell"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EyMlI2RlXWs-","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","    \n","    # Constructor method\n","    def __init__(self, output_dims, emb_dims, hid_dims, n_layers, dropout):\n","        super().__init__()\n","        \n","        # Model layers\n","        self.output_dims = output_dims\n","        self.hid_dims = hid_dims\n","        self.n_layers = n_layers\n","        self.embedding = nn.Embedding(output_dims, emb_dims)\n","        self.rnn = nn.LSTM(emb_dims, hid_dims, n_layers, dropout = dropout)\n","        self.fc_out = nn.Linear(hid_dims, output_dims)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    # Forward method for training\n","    def forward(self, input, h, cell):\n","              \n","        # Model execution\n","        input = input.unsqueeze(0)   \n","        embedded = self.dropout(self.embedding(input))     \n","        output, (h, cell) = self.rnn(embedded, (h, cell))\n","        pred = self.fc_out(output.squeeze(0))\n","        \n","        return pred, h, cell"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJ77yQPaX5aD","colab_type":"code","colab":{}},"source":["class Seq2Seq(nn.Module):\n","    \n","    # Constructor method\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        # Model components\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","    # Forward method for training\n","    def forward(self, src, trg, teacher_forcing_rate = 0.5):\n","        \n","        # Model execution\n","        batch_size = trg.shape[1]\n","        target_length = trg.shape[0]\n","        target_vocab_size = self.decoder.output_dims\n","        outputs = torch.zeros(target_length, batch_size, target_vocab_size).to(self.device)\n","        h, cell = self.encoder(src)\n","        input = trg[0,:]\n","        \n","        for t in range(1, target_length):\n","\n","            output, h, cell = self.decoder(input, h, cell)\n","            outputs[t] = output\n","            top = output.argmax(1) \n","            input = trg[t] if (random.random() < teacher_forcing_rate) else top\n","        \n","        return outputs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtIpLsEXavxJ","colab_type":"code","colab":{}},"source":["# Hyperparameters\n","batch_size = 32\n","input_dimensions = len(SOURCE.vocab)\n","output_dimensions = len(TARGET.vocab)\n","encoder_embedding_dimensions = 256\n","decoder_embedding_dimensions = 256\n","hidden_layer_dimensions = 512\n","num_layers = 2\n","encoder_dropout = 0.5\n","decoder_dropout = 0.5\n","epochs = 30\n","grad_clip = 1\n","lowest_validation_loss = float('inf')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VjbQcEyLazAU","colab_type":"code","colab":{}},"source":["# Data generators\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), \n","                                                                        batch_size = batch_size, \n","                                                                        device = device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6GJcaetja-1F","colab_type":"code","colab":{}},"source":["# Enconder instance\n","encod = Encoder(input_dimensions, \n","                encoder_embedding_dimensions,\n","                hidden_layer_dimensions, \n","                num_layers, \n","                encoder_dropout)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pDq9jVO2bTfD","colab_type":"code","colab":{}},"source":["# Decor instance\n","decod = Decoder(output_dimensions, \n","                decoder_embedding_dimensions,\n","                hidden_layer_dimensions, \n","                num_layers, \n","                decoder_dropout)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1pv6UscDbVlj","colab_type":"code","colab":{}},"source":["# Model instance\n","model = Seq2Seq(encod, decod, device).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YDpfKx5bbY51","colab_type":"code","outputId":"0bb52741-48d0-44df-db65-3cdaab936e3e","executionInfo":{"status":"ok","timestamp":1590356403465,"user_tz":180,"elapsed":11170,"user":{"displayName":"Matheus Schmitz","photoUrl":"","userId":"05041072222578354690"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["# Create model\n","model"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(5893, 256)\n","    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(7855, 256)\n","    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n","    (fc_out): Linear(in_features=512, out_features=7855, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":168}]},{"cell_type":"code","metadata":{"id":"Hv_X9VdfbcxY","colab_type":"code","colab":{}},"source":["def initialize_weights(m):\n","    for name, param in m.named_parameters():\n","        nn.init.uniform_(param.data, -0.1, 0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4qx3fdaibm7z","colab_type":"code","outputId":"9243e6f3-802c-4d44-ccea-2f6a9e548554","executionInfo":{"status":"ok","timestamp":1590356404990,"user_tz":180,"elapsed":10938,"user":{"displayName":"Matheus Schmitz","photoUrl":"","userId":"05041072222578354690"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["# Including the weight initialization function on the model\n","model.apply(initialize_weights)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(5893, 256)\n","    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(7855, 256)\n","    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n","    (fc_out): Linear(in_features=512, out_features=7855, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":170}]},{"cell_type":"code","metadata":{"id":"2F5JPjqMdyzv","colab_type":"code","colab":{}},"source":["# Defining the loss function to calculate model error\n","criterion = nn.CrossEntropyLoss(ignore_index = TARGET.vocab.stoi[TARGET.pad_token])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k8zmJQsLdy2L","colab_type":"code","colab":{}},"source":["# Creating an optimizer to update the model weights after each epoch\n","optimizer = optim.Adam(model.parameters())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fsniFs59bt69","colab_type":"code","colab":{}},"source":["def train_model(model, iterator, optimizer, criterion, clip):\n","    \n","    # Initialize the training method\n","    model.train()\n","    \n","    # Initialize epoch error\n","    epoch_loss = 0\n","    \n","    # Loop through iterator (data generator)\n","    for i, batch in enumerate(iterator):\n","        \n","        # Collect source and target data\n","        src = batch.src\n","        trg = batch.trg\n","        \n","        # Zero gradients\n","        optimizer.zero_grad()\n","        \n","        # Predict\n","        output = model(src, trg)\n","        \n","        # Adjust prediction shape\n","        output_dims = output.shape[-1]\n","        output = output[1:].view(-1, output_dims)\n","        trg = trg[1:].view(-1)\n","        \n","        # Calculate loss\n","        loss = criterion(output, trg)\n","        \n","        # Initialize backpropagation\n","        loss.backward()\n","        \n","        # Calculate the derivative gradients to update weights\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        # Apply weight optimization\n","        optimizer.step()\n","        \n","        # Store epoch error\n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CksvU0HAb3Js","colab_type":"code","colab":{}},"source":["def evaluate_model(model, iterator, criterion):\n","    \n","    # Initialize evaluation method\n","    model.eval()\n","    \n","    # Initialize epoch error\n","    epoch_loss = 0\n","    \n","    # Predicting\n","    with torch.no_grad():\n","    \n","        # Loop through iterator (data generator)\n","        for i, batch in enumerate(iterator):\n","\n","            # Extract source and target data\n","            src = batch.src\n","            trg = batch.trg\n","\n","            # Predict\n","            output = model(src, trg, 0)\n","\n","            # Adjust prediction shape\n","            output_dim = output.shape[-1]\n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            # Model loss\n","            loss = criterion(output, trg)\n","            \n","            # Store epoch error\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vbHNE_zfczaK","colab_type":"text"},"source":["# Train Model"]},{"cell_type":"code","metadata":{"id":"jNi9-86xcuyN","colab_type":"code","outputId":"5b003904-616b-4994-827f-4d1203a8e0bd","executionInfo":{"status":"ok","timestamp":1590357495386,"user_tz":180,"elapsed":1070040,"user":{"displayName":"Matheus Schmitz","photoUrl":"","userId":"05041072222578354690"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Loop through epochs to train odel\n","for epoch in range(epochs):\n","    \n","    # Store start time\n","    start_time = time.time()\n","    \n","    # Training\n","    train_loss = train_model(model, train_iterator, optimizer, criterion, grad_clip)\n","    \n","    # Validation\n","    valid_loss = evaluate_model(model, valid_iterator, criterion)\n","    \n","    # Store end time\n","    end_time = time.time()\n","    \n","    # Check lowest error and save the model by doing a checkpoint of the best performing model\n","    if valid_loss < lowest_validation_loss:\n","        lowest_validation_loss = valid_loss\n","        torch.save(model.state_dict(), 'models/seq2seq.pt')\n","    \n","    # Print\n","    print(f'Epoch: {epoch+1:02} | Time: {np.round(end_time-start_time,0)}s')\n","    print(f'\\t Training error: {train_loss:.4f}')\n","    print(f'\\t Validation Error: {valid_loss:.4f}')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Time: 53.0s\n","\t Training error: 3.0340\n","\t Validation Error: 3.6917\n","Epoch: 02 | Time: 53.0s\n","\t Training error: 2.7115\n","\t Validation Error: 3.6485\n","Epoch: 03 | Time: 53.0s\n","\t Training error: 2.5477\n","\t Validation Error: 3.5898\n","Epoch: 04 | Time: 53.0s\n","\t Training error: 2.4221\n","\t Validation Error: 3.5336\n","Epoch: 05 | Time: 53.0s\n","\t Training error: 2.2868\n","\t Validation Error: 3.5662\n","Epoch: 06 | Time: 53.0s\n","\t Training error: 2.1759\n","\t Validation Error: 3.6335\n","Epoch: 07 | Time: 53.0s\n","\t Training error: 2.0799\n","\t Validation Error: 3.5997\n","Epoch: 08 | Time: 53.0s\n","\t Training error: 1.9717\n","\t Validation Error: 3.6085\n","Epoch: 09 | Time: 54.0s\n","\t Training error: 1.9058\n","\t Validation Error: 3.6265\n","Epoch: 10 | Time: 54.0s\n","\t Training error: 1.8162\n","\t Validation Error: 3.6797\n","Epoch: 11 | Time: 54.0s\n","\t Training error: 1.7466\n","\t Validation Error: 3.6288\n","Epoch: 12 | Time: 54.0s\n","\t Training error: 1.6704\n","\t Validation Error: 3.6528\n","Epoch: 13 | Time: 54.0s\n","\t Training error: 1.6080\n","\t Validation Error: 3.7270\n","Epoch: 14 | Time: 54.0s\n","\t Training error: 1.5554\n","\t Validation Error: 3.7336\n","Epoch: 15 | Time: 54.0s\n","\t Training error: 1.4994\n","\t Validation Error: 3.7599\n","Epoch: 16 | Time: 53.0s\n","\t Training error: 1.4450\n","\t Validation Error: 3.7641\n","Epoch: 17 | Time: 54.0s\n","\t Training error: 1.3961\n","\t Validation Error: 3.7791\n","Epoch: 18 | Time: 54.0s\n","\t Training error: 1.3473\n","\t Validation Error: 3.8986\n","Epoch: 19 | Time: 54.0s\n","\t Training error: 1.3109\n","\t Validation Error: 3.9076\n","Epoch: 20 | Time: 54.0s\n","\t Training error: 1.2673\n","\t Validation Error: 3.9060\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Tv_hNzGueMnY","colab_type":"text"},"source":["# Evaluate Model"]},{"cell_type":"code","metadata":{"id":"2Zm_CblteOU_","colab_type":"code","outputId":"958066e1-5fe7-4b93-f70c-7bdfc6e878ff","executionInfo":{"status":"ok","timestamp":1590357495390,"user_tz":180,"elapsed":1067936,"user":{"displayName":"Matheus Schmitz","photoUrl":"","userId":"05041072222578354690"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Loading trained model\n","model.load_state_dict(torch.load('models/seq2seq.pt'))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":182}]},{"cell_type":"code","metadata":{"id":"GMvUsK7lj5yD","colab_type":"code","colab":{}},"source":["# Evaluate model\n","test_loss = evaluate_model(model, test_iterator, criterion)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TEtkBwOEkBIv","colab_type":"code","outputId":"00a7c702-056d-45c6-c313-24aa7efc56c9","executionInfo":{"status":"ok","timestamp":1590357495879,"user_tz":180,"elapsed":1068126,"user":{"displayName":"Matheus Schmitz","photoUrl":"","userId":"05041072222578354690"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Test error\n","print(f'Test Error: {test_loss:.4f}')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test Error: 3.5281\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qVzq8rnAkH9J","colab_type":"text"},"source":["# Translating"]},{"cell_type":"code","metadata":{"id":"OPa6bDNvkJMt","colab_type":"code","colab":{}},"source":["def translate_language(model, iterator, num_translations = 5):\n","    \n","    with torch.no_grad():\n","    \n","        # Loop through iterador\n","        for i, batch in enumerate(iterator):\n","            \n","            # While inside the num_translations, translate\n","            if i < num_translations :\n","                \n","                # Extract SOURCE and TARGET\n","                # Doing so to compare the predicted translation with the true translation\n","                src = batch.src\n","                trg = batch.trg\n","\n","                # Model prediction\n","                output = model(src, trg, 0)\n","                \n","                # All predictions\n","                preds = torch.tensor([[torch.argmax(x).item()] for x in output])\n","                \n","                # Prints\n","                print('Original English Text: ' + str([SOURCE.vocab.itos[x] for x in src][1:-1][::-1]))\n","                print('Translated German Text (Expected Output): ' + str([TARGET.vocab.itos[x] for x in trg][1:-1]))\n","                print('Translated German Text (Model Prediction): ' + str([TARGET.vocab.itos[x] for x in preds][1:-1]))\n","                print('\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TXyW-atZk5sa","colab_type":"code","colab":{}},"source":["# Generating random text to be translated\n","_, _, iterator_translate = BucketIterator.splits((train_data, valid_data, test_data), \n","                                                 batch_size = 1, \n","                                                 device = device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kARtfOGnlGTl","colab_type":"code","outputId":"fbbaa08c-1d59-4081-c3e2-72ccce878a8d","executionInfo":{"status":"ok","timestamp":1590357495882,"user_tz":180,"elapsed":1067477,"user":{"displayName":"Matheus Schmitz","photoUrl":"","userId":"05041072222578354690"}},"colab":{"base_uri":"https://localhost:8080/","height":442}},"source":["# Translation\n","translation = translate_language(model, iterator_translate)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Original English Text: ['two', 'men', 'wearing', 'hats', '.']\n","Translated German Text (Expected Output): ['zwei', 'männer', 'mit', 'mützen', '.']\n","Translated German Text (Model Prediction): ['zwei', 'männer', 'mit', 'sonnenbrillen', '.']\n","\n","\n","Original English Text: ['young', 'woman', 'climbing', 'rock', 'face']\n","Translated German Text (Expected Output): ['junge', 'frau', 'klettert', 'auf', 'felswand']\n","Translated German Text (Model Prediction): ['eine', 'junge', 'frau', ',', 'die']\n","\n","\n","Original English Text: ['a', 'woman', 'is', 'playing', 'volleyball', '.']\n","Translated German Text (Expected Output): ['eine', 'frau', 'spielt', 'volleyball', '.']\n","Translated German Text (Model Prediction): ['eine', 'frau', 'spielt', 'volleyball', '.']\n","\n","\n","Original English Text: ['three', 'men', 'are', 'walking', 'up', 'hill', '.']\n","Translated German Text (Expected Output): ['drei', 'männer', 'gehen', 'bergauf', '.']\n","Translated German Text (Model Prediction): ['drei', 'männer', 'gehen', 'durch', 'den']\n","\n","\n","Original English Text: ['an', 'army', 'officer', 'is', 'inspecting', 'something', '.']\n","Translated German Text (Expected Output): ['ein', '<unk>', 'inspiziert', 'etwas', '.']\n","Translated German Text (Model Prediction): ['ein', '<unk>', 'wird', '<unk>', '.']\n","\n","\n"],"name":"stdout"}]}]}